// internal/infrastructure/email/email_pipeline_impl.go
package email

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github.com/audetv/urms/internal/core/domain"
	"github.com/audetv/urms/internal/core/ports"
)

// EmailPipelineImpl —Ä–µ–∞–ª–∏–∑—É–µ—Ç ports.EmailPipeline
type EmailPipelineImpl struct {
	fetcher         ports.EmailFetcher
	queue           ports.MessageQueue
	workerPool      ports.WorkerPool
	strategy        ports.PipelineStrategy
	searchFactory   ports.SearchStrategyFactory
	logger          ports.Logger
	criteriaBuilder *FetchCriteriaBuilder
	metrics         *PipelineMetricsCollector
	status          *PipelineStatus
	shutdownTimeout time.Duration
	mu              sync.RWMutex
}

// PipelineMetricsCollector —Å–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ pipeline
type PipelineMetricsCollector struct {
	startTime      time.Time
	totalProcessed int64
	totalFailed    int64
	lastProcessed  time.Time
	processingTime time.Duration
	mu             sync.RWMutex
}

// PipelineStatus –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ pipeline
type PipelineStatus struct {
	status       string
	activeSince  time.Time
	currentPhase string
	lastError    string
	mu           sync.RWMutex
}

// NewEmailPipelineImpl —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä Email Pipeline
func NewEmailPipelineImpl(
	fetcher ports.EmailFetcher,
	queue ports.MessageQueue,
	workerPool ports.WorkerPool,
	strategy ports.PipelineStrategy,
	searchFactory ports.SearchStrategyFactory,
	logger ports.Logger,
) *EmailPipelineImpl {

	return &EmailPipelineImpl{
		fetcher:         fetcher,
		queue:           queue,
		workerPool:      workerPool,
		strategy:        strategy,
		searchFactory:   searchFactory,
		logger:          logger,
		criteriaBuilder: NewFetchCriteriaBuilder(searchFactory, fetcher, logger),
		metrics:         &PipelineMetricsCollector{startTime: time.Now()},
		status:          &PipelineStatus{status: "created"},
		shutdownTimeout: 30 * time.Second,
	}
}

// Start –∑–∞–ø—É—Å–∫–∞–µ—Ç pipeline processing
func (p *EmailPipelineImpl) Start(ctx context.Context) error {
	p.mu.Lock()
	defer p.mu.Unlock()

	p.logger.Info(ctx, "üöÄ Starting email processing pipeline")

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–¥–æ—Ä–æ–≤—å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
	if err := p.healthCheck(ctx); err != nil {
		return fmt.Errorf("pipeline health check failed: %w", err)
	}

	// –ó–∞–ø—É—Å–∫–∞–µ–º worker pool
	if err := p.workerPool.Start(ctx); err != nil {
		return fmt.Errorf("failed to start worker pool: %w", err)
	}

	// –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
	p.status.setStatus("running", "initialization")
	p.status.activeSince = time.Now()

	p.logger.Info(ctx, "‚úÖ Email pipeline started successfully",
		"provider_type", p.fetcher.GetProviderType(),
		"worker_count", p.strategy.GetWorkerCount(),
		"batch_size", p.strategy.GetBatchSize())

	return nil
}

// Stop –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç pipeline
func (p *EmailPipelineImpl) Stop(ctx context.Context) error {
	p.mu.Lock()
	defer p.mu.Unlock()

	p.logger.Info(ctx, "üõë Stopping email processing pipeline")

	// –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
	p.status.setStatus("stopping", "shutdown")

	// –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —Ç–∞–π–º–∞—É—Ç–æ–º –¥–ª—è graceful shutdown
	shutdownCtx, cancel := context.WithTimeout(ctx, p.shutdownTimeout)
	defer cancel()

	// –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º worker pool
	if err := p.workerPool.Stop(shutdownCtx); err != nil {
		p.logger.Error(ctx, "Failed to stop worker pool gracefully",
			"error", err.Error())
	}

	// –û—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥—å
	if err := p.queue.Clear(shutdownCtx); err != nil {
		p.logger.Warn(ctx, "Failed to clear message queue",
			"error", err.Error())
	}

	p.status.setStatus("stopped", "shutdown_complete")

	p.logger.Info(ctx, "‚úÖ Email pipeline stopped successfully",
		"total_processed", p.metrics.getTotalProcessed(),
		"total_failed", p.metrics.getTotalFailed(),
		"uptime", time.Since(p.status.activeSince).String())

	return nil
}

// ProcessBatch –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –±–∞—Ç—á —Å–æ–æ–±—â–µ–Ω–∏–π
func (p *EmailPipelineImpl) ProcessBatch(ctx context.Context) error {
	p.mu.RLock()
	defer p.mu.RUnlock()

	if p.status.getStatus() != "running" {
		return fmt.Errorf("pipeline is not running, current status: %s", p.status.getStatus())
	}

	p.logger.Info(ctx, "üîç Starting email batch processing")

	startTime := time.Now()
	p.status.setCurrentPhase("fetching")

	// 1. PHASE: Fetch emails
	messages, err := p.fetcher.FetchBatch(ctx, p.createFetchCriteria())
	if err != nil {
		p.metrics.recordFailure()
		p.status.setLastError(fmt.Sprintf("fetch failed: %v", err))
		return fmt.Errorf("failed to fetch emails: %w", err)
	}

	p.logger.Info(ctx, "‚úÖ Email fetch completed",
		"message_count", len(messages),
		"fetch_duration", time.Since(startTime).String())

	if len(messages) == 0 {
		p.logger.Info(ctx, "üì≠ No new messages to process")
		return nil
	}

	p.status.setCurrentPhase("queuing")

	// 2. PHASE: Enqueue messages
	if err := p.queue.Enqueue(ctx, messages); err != nil {
		p.metrics.recordFailure()
		p.status.setLastError(fmt.Sprintf("enqueue failed: %v", err))
		return fmt.Errorf("failed to enqueue messages: %w", err)
	}

	p.logger.Debug(ctx, "‚úÖ Messages enqueued successfully",
		"queue_size_after", p.getQueueSize(ctx))

	p.status.setCurrentPhase("processing")

	// 3. PHASE: Process messages through worker pool
	processedCount, failedCount := p.processMessages(ctx, messages)

	// 4. PHASE: Update metrics
	totalDuration := time.Since(startTime)
	p.metrics.recordProcessing(processedCount, failedCount, totalDuration)

	p.logger.Info(ctx, "üéâ Email batch processing completed",
		"total_messages", len(messages),
		"processed", processedCount,
		"failed", failedCount,
		"success_rate", fmt.Sprintf("%.1f%%", float64(processedCount)/float64(len(messages))*100),
		"total_duration", totalDuration.String(),
		"throughput", fmt.Sprintf("%.1f msg/sec", float64(len(messages))/totalDuration.Seconds()))

	p.status.setCurrentPhase("idle")

	return nil
}

// Health –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–¥–æ—Ä–æ–≤—å—è pipeline
func (p *EmailPipelineImpl) Health(ctx context.Context) (*ports.PipelineHealth, error) {
	components := make(map[string]string)

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–¥–æ—Ä–æ–≤—å–µ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
	if err := p.fetcher.Health(ctx); err != nil {
		components["fetcher"] = fmt.Sprintf("unhealthy: %v", err)
	} else {
		components["fetcher"] = "healthy"
	}

	if err := p.queue.Health(ctx); err != nil {
		components["queue"] = fmt.Sprintf("unhealthy: %v", err)
	} else {
		components["queue"] = "healthy"
	}

	if err := p.workerPool.Health(ctx); err != nil {
		components["worker_pool"] = fmt.Sprintf("unhealthy: %v", err)
	} else {
		components["worker_pool"] = "healthy"
	}

	if err := p.searchFactory.Health(ctx); err != nil {
		components["search_factory"] = fmt.Sprintf("unhealthy: %v", err)
	} else {
		components["search_factory"] = "healthy"
	}

	// –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å
	overallStatus := "healthy"
	for _, status := range components {
		if status != "healthy" {
			overallStatus = "degraded"
			break
		}
	}

	return &ports.PipelineHealth{
		Status:     overallStatus,
		Timestamp:  time.Now(),
		Components: components,
	}, nil
}

// GetMetrics –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ pipeline
func (p *EmailPipelineImpl) GetMetrics(ctx context.Context) (*ports.PipelineMetrics, error) {
	queueSize, _ := p.queue.Size(ctx)
	workerMetrics := p.workerPool.GetMetrics(ctx)

	return &ports.PipelineMetrics{
		ProviderType:     p.fetcher.GetProviderType(),
		Uptime:           time.Since(p.metrics.startTime),
		TotalProcessed:   p.metrics.getTotalProcessed(),
		TotalFailed:      p.metrics.getTotalFailed(),
		CurrentQueueSize: queueSize,
		WorkersActive:    workerMetrics.WorkersActive,
		WorkersTotal:     workerMetrics.WorkersTotal,
		LastProcessed:    p.metrics.lastProcessed,
		AvgProcessTime:   p.metrics.getAvgProcessTime(),
	}, nil
}

// createFetchCriteria —Å–æ–∑–¥–∞–µ—Ç –∫—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è –≤—ã–±–æ—Ä–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
func (p *EmailPipelineImpl) createFetchCriteria() ports.FetchCriteria {
	return p.criteriaBuilder.BuildStandardCriteria(context.Background())
}

// processMessages –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ worker pool
func (p *EmailPipelineImpl) processMessages(ctx context.Context, messages []domain.EmailMessage) (int, int) {
	var wg sync.WaitGroup
	processed := 0
	failed := 0
	var mu sync.Mutex

	for i, msg := range messages {
		select {
		case <-ctx.Done():
			p.logger.Warn(ctx, "Message processing cancelled by context",
				"processed", processed, "failed", failed, "remaining", len(messages)-i)
			return processed, failed
		default:
			wg.Add(1)
			go func(msg domain.EmailMessage) {
				defer wg.Done()

				if err := p.workerPool.Submit(ctx, msg); err != nil {
					p.logger.Error(ctx, "Failed to submit message to worker pool",
						"message_id", msg.MessageID, "error", err.Error())
					mu.Lock()
					failed++
					mu.Unlock()
				} else {
					mu.Lock()
					processed++
					mu.Unlock()
				}
			}(msg)
		}
	}

	wg.Wait()
	return processed, failed
}

// healthCheck –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–¥–æ—Ä–æ–≤—å–µ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
func (p *EmailPipelineImpl) healthCheck(ctx context.Context) error {
	components := []struct {
		name   string
		health func(ctx context.Context) error
	}{
		{"fetcher", p.fetcher.Health},
		{"queue", p.queue.Health},
		{"worker_pool", p.workerPool.Health},
		{"search_factory", p.searchFactory.Health},
	}

	for _, component := range components {
		if err := component.health(ctx); err != nil {
			return fmt.Errorf("%s health check failed: %w", component.name, err)
		}
	}

	return nil
}

// getQueueSize –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏
func (p *EmailPipelineImpl) getQueueSize(ctx context.Context) int {
	size, err := p.queue.Size(ctx)
	if err != nil {
		p.logger.Warn(ctx, "Failed to get queue size", "error", err.Error())
		return 0
	}
	return size
}

// –ú–µ—Ç–æ–¥—ã –¥–ª—è PipelineMetricsCollector
func (m *PipelineMetricsCollector) recordProcessing(processed, failed int, duration time.Duration) {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.totalProcessed += int64(processed)
	m.totalFailed += int64(failed)
	m.processingTime += duration
	m.lastProcessed = time.Now()
}

func (m *PipelineMetricsCollector) recordFailure() {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.totalFailed++
}

func (m *PipelineMetricsCollector) getTotalProcessed() int64 {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.totalProcessed
}

func (m *PipelineMetricsCollector) getTotalFailed() int64 {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.totalFailed
}

func (m *PipelineMetricsCollector) getAvgProcessTime() time.Duration {
	m.mu.RLock()
	defer m.mu.RUnlock()
	if m.totalProcessed == 0 {
		return 0
	}
	return m.processingTime / time.Duration(m.totalProcessed)
}

// –ú–µ—Ç–æ–¥—ã –¥–ª—è PipelineStatus
func (s *PipelineStatus) setStatus(status, phase string) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.status = status
	s.currentPhase = phase
}

func (s *PipelineStatus) getStatus() string {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return s.status
}

func (s *PipelineStatus) setCurrentPhase(phase string) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.currentPhase = phase
}

func (s *PipelineStatus) setLastError(error string) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.lastError = error
}
