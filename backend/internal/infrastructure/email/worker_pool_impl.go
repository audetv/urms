// internal/infrastructure/email/worker_pool_impl.go
package email

import (
	"context"
	"fmt"
	"sync"
	"sync/atomic"
	"time"

	"github.com/audetv/urms/internal/core/domain"
	"github.com/audetv/urms/internal/core/ports"
)

// WorkerPoolImpl —Ä–µ–∞–ª–∏–∑—É–µ—Ç ports.WorkerPool
type WorkerPoolImpl struct {
	workers          []*Worker
	jobQueue         chan domain.EmailMessage
	workerCount      int
	messageProcessor ports.MessageProcessor
	logger           ports.Logger
	metrics          *WorkerPoolMetrics
	shutdownChan     chan struct{}
	wg               sync.WaitGroup
	mu               sync.RWMutex
	isRunning        bool
}

// Worker –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –≤–æ—Ä–∫–µ—Ä–∞
type Worker struct {
	id        int
	jobQueue  <-chan domain.EmailMessage
	processor ports.MessageProcessor
	logger    ports.Logger
	metrics   *WorkerPoolMetrics
	shutdown  <-chan struct{}
	wg        *sync.WaitGroup
}

// WorkerPoolMetrics —Å–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ worker pool
type WorkerPoolMetrics struct {
	totalProcessed      int64
	totalFailed         int64
	activeWorkers       int32
	idleWorkers         int32
	totalProcessingTime time.Duration
	lastActivity        time.Time
	mu                  sync.RWMutex
}

// NewWorkerPoolImpl —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π worker pool
func NewWorkerPoolImpl(
	workerCount int,
	queueSize int,
	messageProcessor ports.MessageProcessor,
	logger ports.Logger,
) *WorkerPoolImpl {

	return &WorkerPoolImpl{
		workers:          make([]*Worker, 0, workerCount),
		jobQueue:         make(chan domain.EmailMessage, queueSize),
		workerCount:      workerCount,
		messageProcessor: messageProcessor,
		logger:           logger,
		metrics:          &WorkerPoolMetrics{},
		shutdownChan:     make(chan struct{}),
		isRunning:        false,
	}
}

// Start –∑–∞–ø—É—Å–∫–∞–µ—Ç worker pool
func (wp *WorkerPoolImpl) Start(ctx context.Context) error {
	wp.mu.Lock()
	defer wp.mu.Unlock()

	if wp.isRunning {
		return fmt.Errorf("worker pool is already running")
	}

	wp.logger.Info(ctx, "üöÄ Starting worker pool",
		"worker_count", wp.workerCount,
		"queue_size", cap(wp.jobQueue))

	// –°–æ–∑–¥–∞–µ–º –≤–æ—Ä–∫–µ—Ä—ã
	for i := 0; i < wp.workerCount; i++ {
		worker := &Worker{
			id:        i + 1,
			jobQueue:  wp.jobQueue,
			processor: wp.messageProcessor,
			logger:    wp.logger,
			metrics:   wp.metrics,
			shutdown:  wp.shutdownChan,
			wg:        &wp.wg,
		}
		wp.workers = append(wp.workers, worker)
		wp.wg.Add(1)
		go worker.start(ctx)
	}

	wp.isRunning = true
	atomic.StoreInt32(&wp.metrics.idleWorkers, int32(wp.workerCount))

	wp.logger.Info(ctx, "‚úÖ Worker pool started successfully",
		"total_workers", len(wp.workers),
		"queue_capacity", cap(wp.jobQueue))

	return nil
}

// Stop –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç worker pool
func (wp *WorkerPoolImpl) Stop(ctx context.Context) error {
	wp.mu.Lock()
	defer wp.mu.Unlock()

	if !wp.isRunning {
		return nil // –£–∂–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
	}

	wp.logger.Info(ctx, "üõë Stopping worker pool")

	// –ó–∞–∫—Ä—ã–≤–∞–µ–º –∫–∞–Ω–∞–ª shutdown —á—Ç–æ–±—ã —Å–∏–≥–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–æ—Ä–∫–µ—Ä–∞–º
	close(wp.shutdownChan)

	// –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤–æ—Ä–∫–µ—Ä–æ–≤
	done := make(chan struct{})
	go func() {
		wp.wg.Wait()
		close(done)
	}()

	// –ñ–¥–µ–º —Å —Ç–∞–π–º–∞—É—Ç–æ–º
	select {
	case <-done:
		wp.logger.Info(ctx, "‚úÖ Worker pool stopped gracefully")
	case <-ctx.Done():
		wp.logger.Warn(ctx, "Worker pool stop timed out")
		return ctx.Err()
	}

	// –ó–∞–∫—Ä—ã–≤–∞–µ–º job queue
	close(wp.jobQueue)
	wp.isRunning = false

	wp.logger.Info(ctx, "üéØ Worker pool shutdown completed",
		"total_processed", wp.metrics.getTotalProcessed(),
		"total_failed", wp.metrics.getTotalFailed(),
		"avg_process_time", wp.metrics.getAvgProcessTime())

	return nil
}

// Submit –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ worker pool
func (wp *WorkerPoolImpl) Submit(ctx context.Context, message domain.EmailMessage) error {
	if !wp.isRunning {
		return fmt.Errorf("worker pool is not running")
	}

	select {
	case wp.jobQueue <- message:
		wp.logger.Debug(ctx, "Message submitted to worker pool",
			"message_id", message.MessageID,
			"queue_size", len(wp.jobQueue),
			"queue_capacity", cap(wp.jobQueue))
		return nil
	case <-ctx.Done():
		return ctx.Err()
	case <-wp.shutdownChan:
		return fmt.Errorf("worker pool is shutting down")
	default:
		// –û—á–µ—Ä–µ–¥—å –∑–∞–ø–æ–ª–Ω–µ–Ω–∞
		wp.logger.Warn(ctx, "Worker pool queue is full, message rejected",
			"message_id", message.MessageID,
			"queue_size", len(wp.jobQueue))
		return fmt.Errorf("worker pool queue is full")
	}
}

// GetMetrics –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ worker pool
func (wp *WorkerPoolImpl) GetMetrics(ctx context.Context) *ports.WorkerMetrics {
	wp.metrics.mu.RLock()
	defer wp.metrics.mu.RUnlock()

	activeWorkers := atomic.LoadInt32(&wp.metrics.activeWorkers)
	idleWorkers := atomic.LoadInt32(&wp.metrics.idleWorkers)

	return &ports.WorkerMetrics{
		WorkersActive:  int(activeWorkers),
		WorkersIdle:    int(idleWorkers),
		WorkersTotal:   wp.workerCount,
		TasksProcessed: wp.metrics.getTotalProcessed(),
		TasksFailed:    wp.metrics.getTotalFailed(),
		AvgProcessTime: wp.metrics.getAvgProcessTime(),
		QueueWaitTime:  wp.calculateQueueWaitTime(),
		LastActivity:   wp.metrics.lastActivity,
	}
}

// Health –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–¥–æ—Ä–æ–≤—å–µ worker pool
func (wp *WorkerPoolImpl) Health(ctx context.Context) error {
	wp.mu.RLock()
	defer wp.mu.RUnlock()

	if !wp.isRunning {
		return fmt.Errorf("worker pool is not running")
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –≤–æ—Ä–∫–µ—Ä—ã
	activeWorkers := atomic.LoadInt32(&wp.metrics.activeWorkers)
	if activeWorkers == 0 && wp.metrics.getTotalProcessed() > 0 {
		return fmt.Errorf("no active workers but pool has processed messages")
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞ –ª–∏ –æ—á–µ—Ä–µ–¥—å
	queueUtilization := float64(len(wp.jobQueue)) / float64(cap(wp.jobQueue)) * 100
	if queueUtilization > 80 {
		wp.logger.Warn(ctx, "Worker pool queue utilization is high",
			"utilization_percent", fmt.Sprintf("%.1f%%", queueUtilization),
			"queue_size", len(wp.jobQueue),
			"queue_capacity", cap(wp.jobQueue))
	}

	wp.logger.Debug(ctx, "Worker pool health check passed",
		"active_workers", activeWorkers,
		"idle_workers", atomic.LoadInt32(&wp.metrics.idleWorkers),
		"queue_utilization", fmt.Sprintf("%.1f%%", queueUtilization))

	return nil
}

// calculateQueueWaitTime –≤—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –≤ –æ—á–µ—Ä–µ–¥–∏
func (wp *WorkerPoolImpl) calculateQueueWaitTime() time.Duration {
	// –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ - –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Å–ª–æ–∂–Ω–µ–µ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
	queueSize := len(wp.jobQueue)
	if queueSize == 0 {
		return 0
	}

	// –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ –∫–∞–∂–¥—ã–π –≤–æ—Ä–∫–µ—Ä –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç 1 —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Å–µ–∫—É–Ω–¥—É
	estimatedWait := time.Duration(queueSize) * time.Second / time.Duration(wp.workerCount)
	return estimatedWait
}

// start –∑–∞–ø—É—Å–∫–∞–µ—Ç –≤–æ—Ä–∫–µ—Ä–∞
func (w *Worker) start(ctx context.Context) {
	defer w.wg.Done()

	w.logger.Info(ctx, "üë∑ Worker started",
		"worker_id", w.id)

	for {
		select {
		case message, ok := <-w.jobQueue:
			if !ok {
				// –ö–∞–Ω–∞–ª –∑–∞–∫—Ä—ã—Ç
				w.logger.Debug(ctx, "Worker stopping - job queue closed",
					"worker_id", w.id)
				return
			}
			w.processMessage(ctx, message)

		case <-w.shutdown:
			w.logger.Debug(ctx, "Worker stopping - shutdown signal",
				"worker_id", w.id)
			return

		case <-ctx.Done():
			w.logger.Debug(ctx, "Worker stopping - context cancelled",
				"worker_id", w.id)
			return
		}
	}
}

// processMessage –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ
func (w *Worker) processMessage(ctx context.Context, message domain.EmailMessage) {
	startTime := time.Now()

	// –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
	atomic.AddInt32(&w.metrics.activeWorkers, 1)
	atomic.AddInt32(&w.metrics.idleWorkers, -1)
	defer func() {
		atomic.AddInt32(&w.metrics.activeWorkers, -1)
		atomic.AddInt32(&w.metrics.idleWorkers, 1)
	}()

	w.logger.Debug(ctx, "Worker processing message",
		"worker_id", w.id,
		"message_id", message.MessageID,
		"subject", message.Subject)

	// –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
	err := w.processor.ProcessIncomingEmail(ctx, message)
	processingTime := time.Since(startTime)

	// –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
	w.metrics.recordProcessing(processingTime, err == nil)

	if err != nil {
		w.logger.Error(ctx, "Worker failed to process message",
			"worker_id", w.id,
			"message_id", message.MessageID,
			"error", err.Error(),
			"processing_time", processingTime.String())
	} else {
		w.logger.Debug(ctx, "Worker successfully processed message",
			"worker_id", w.id,
			"message_id", message.MessageID,
			"processing_time", processingTime.String())
	}
}

// –ú–µ—Ç–æ–¥—ã –¥–ª—è WorkerPoolMetrics
func (m *WorkerPoolMetrics) recordProcessing(duration time.Duration, success bool) {
	m.mu.Lock()
	defer m.mu.Unlock()

	if success {
		m.totalProcessed++
	} else {
		m.totalFailed++
	}
	m.totalProcessingTime += duration
	m.lastActivity = time.Now()
}

func (m *WorkerPoolMetrics) getTotalProcessed() int64 {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.totalProcessed
}

func (m *WorkerPoolMetrics) getTotalFailed() int64 {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.totalFailed
}

func (m *WorkerPoolMetrics) getAvgProcessTime() time.Duration {
	m.mu.RLock()
	defer m.mu.RUnlock()
	if m.totalProcessed == 0 {
		return 0
	}
	return m.totalProcessingTime / time.Duration(m.totalProcessed)
}
